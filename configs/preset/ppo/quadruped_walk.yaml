env:
  name: "dm_control/quadruped-walk-v0"
  limit_ep_steps: 1000
  normalize: true

method:
  _target_: stable_baselines3.PPO
  policy_kwargs:
    net_arch:
      pi: [256, 256, 256]
      vf: [256, 256, 256]
  learning_rate: 5.0e-5
  batch_size: 128
  ent_coef: 0
  n_steps: 500
  clip_range:
    _target_: pref_rl.config.LinearSchedule
    start: 0.4
    end: 0.0
  gae_lambda: 0.9
  n_epochs: 20
  use_sde: true
  sde_sample_freq: 4

logging:
  log_freq_rollouts: 2
