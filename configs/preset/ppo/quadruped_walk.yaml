env:
  name: "dm_control/quadruped-walk-v0"
  limit_ep_steps: 500

method:
  _target_: stable_baselines3.PPO
  policy_kwargs:
    net_arch:
      pi: [256, 256, 256]
      vf: [256, 256, 256]
  learning_rate: 5.0e-5
  batch_size: 128
  ent_coef: 0
  n_steps: 512
  clip_range:
    _target_: pref_rl.config.LinearSchedule
    start: 0.4
    end: 0.2
  gae_lambda: 0.9
